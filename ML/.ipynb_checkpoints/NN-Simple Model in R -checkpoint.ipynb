{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    " \n",
    "Today we will build a neural network (NN) from scratch. \n",
    "\n",
    "The structure of the NN is shown in the following image:\n",
    "  \n",
    "<img src=\"https://i1.wp.com/res.cloudinary.com/dxqnb8xjb/image/upload/v1539018324/nn_diagram_d7gs7e.png?w=456&ssl=1\" />\n",
    " \n",
    " \n",
    "This NN have three layers: \n",
    "\n",
    "- Input layer: this layer is constitute the input data\n",
    "- Hidden layer: this is the most internal layer. This layer is not visible to the user that is why NN are considered black boxes. \n",
    "- Output layer: this layer will contain our output ($\\hat{y}$)\n",
    "\n",
    "\n",
    "<img src=\"https://cdnpythonmachinelearning.azureedge.net/wp-content/uploads/2017/09/Single-Perceptron.png?x31195\" width=\"600\" height=\"400\" />\n",
    " \n",
    " \n",
    "We proceed with the input layer and calculate the weights and the bias for each of the input (X's):\n",
    " \n",
    "$$ z = W_{i1}^{T}X + b_1 $$\n",
    "\n",
    "This is called the <b> Transfer Function </b>. After that, the resulting vector (z) is passed through an <b> Activation Function </b>. There are many types of activation functions, one of them we yet know, the <b>sigmoid function </b>:\n",
    " \n",
    "$$   \\sigma = 1 / (1 + exp^{-z})  $$\n",
    "\n",
    "Lets code this functions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' the activation function is the sigmoid\n",
    "sigmoid <- function(x) {\n",
    "  1.0 / (1.0 + exp(-x))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward\n",
    " \n",
    "The transfer and activation functions are applyed to the first layer (input layer) and the resuts are passed to the following layer (hidden layer) and both functions are now applied to it. Then the reult is passed to the output layer. Those passes are known as feedforward step. Now we will define this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feedforward\n",
    "feedforward <- function(nn) {\n",
    "  ## activation of the first layer\n",
    "  nn$layer1 <- sigmoid(nn$input %*% nn$weights1)\n",
    "  ## activation of the following layer\n",
    "  nn$output <- sigmoid(nn$layer1 %*% nn$weights2)\n",
    "  return(nn)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, the final feedforward function for our network looks as follows:\n",
    " \n",
    "$$ \\hat{y} = \\sigma(W_2^{T}(\\sigma(W_1^{T}X) + b_1) + b_2 )  $$\n",
    " \n",
    "\n",
    "## Backpropagation\n",
    " \n",
    "The resulting output of the feedforward step gives a result that has a high error (loss). To reduce this error, the weight and bias are corrected by going backwards. This step is known as backpropagation. This is done by the following function:\n",
    " \n",
    "$$  2(y - \\hat{y}) * z(1-z) * X $$\n",
    " \n",
    "where z is\n",
    "\n",
    "$$  z = (W^{T}X + b) $$\n",
    "\n",
    "and $ z(1-z) $ is known as the <b>derivative of the sigmoid function</b>.\n",
    "\n",
    "Now we add the code for the backpropagation function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' the derivative of the activation function\n",
    "sigmoid_derivative <- function(x) {\n",
    "  return(x * (1.0 - x))\n",
    "}\n",
    "\n",
    "## Backpropagation\n",
    "backprop <- function(nn) {\n",
    "  # application of the chain rule to find derivative of the loss function with \n",
    "  # respect to weights2 and weights1\n",
    "    \n",
    "  # `2 * (nn$y - nn$output)` is the derivative of the sigmoid loss function\n",
    "  d_weights2 <- ( t(nn$layer1) %*% (2 * (nn$y - nn$output) * sigmoid_derivative(nn$output)) )\n",
    "\n",
    "  d_weights1 <- ( 2 * (nn$y - nn$output) * sigmoid_derivative(nn$output)) %*% t(nn$weights2)\n",
    "    \n",
    "  d_weights1 <- d_weights1 * sigmoid_derivative(nn$layer1)\n",
    "    \n",
    "  d_weights1 <- t(nn$input) %*% d_weights1\n",
    "  \n",
    "  # update the weights using the derivative (slope) of the loss function\n",
    "  nn$weights1 <- nn$weights1 + d_weights1\n",
    "  nn$weights2 <- nn$weights2 + d_weights2\n",
    "\n",
    "  return(nn)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    " \n",
    "Now that we have all the needed functions for our NN, we have to define the loss function. We will use the Sum of Squared Error: \n",
    "\n",
    "$$  cost = \\sum_{i=1}^{n} {(y - \\hat{y})^{2}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss function: SSE\n",
    "loss_function <- function(nn) {\n",
    "  return(sum((nn$y - nn$output) ^ 2))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And  we define the gradient descent function by running the network (feed)fordward and backward (backpropagation) while recalculating the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GD <- function(nnet, num_iter=100) { # GD if the gradient descend\n",
    "    n <- num_iter\n",
    "\n",
    "    # data frame to store the results of the loss function.\n",
    "    # this data frame is used to produce the plot in the \n",
    "    # next code chunk\n",
    "    loss_df <- data.frame(iteration = 1:n+1, loss = vector(\"numeric\", length = n) )\n",
    "\n",
    "    for (i in seq_len(num_iter)) {\n",
    "      nnet <- feedforward(nnet)\n",
    "      nnet <- backprop(nnet)\n",
    "\n",
    "      # store the result of the loss function.  We will plot this later\n",
    "      loss_df$loss[i] <- loss_function(nnet)\n",
    "    }\n",
    "    # print the predicted outcome next to the actual outcome\n",
    "    yhat <- data.frame(\"Predicted\" = round(nnet$output, 3), \"Actual\" = y)\n",
    "    res <- list(yhat=yhat, loss=loss_df)\n",
    "    return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NeuralNetwork <- function(X, y, num_nodes, num_iter=100) {\n",
    "    # generate a random value between 0 and 1 for each\n",
    "    # element in X.  This will be used as our initial weights\n",
    "    # for layer 1\n",
    "    rand_vector <- runif(ncol(X) * nrow(X))\n",
    "\n",
    "    # convert above vector into a matrix\n",
    "    rand_matrix <- matrix(rand_vector, nrow = ncol(X), ncol = nrow(X), byrow = TRUE)\n",
    "\n",
    "    # this list stores the state of our neural net as it is trained\n",
    "    nnet <- list(input = X,                              # predictor variables\n",
    "                  weights1 = rand_matrix,                 # weights for layer 1\n",
    "                  weights2 = matrix(runif(num_nodes), ncol = 1),  # weights for layer 2\n",
    "                  y = y,                                  # actual observed\n",
    "                  output = matrix(rep(0, times = num_nodes), ncol = 1)   # stores the predicted outcome\n",
    "                 )\n",
    "    return(GD(nnet, num_iter))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we create the data to train the neural network.\n",
    "\n",
    "# predictor variables\n",
    "X <- matrix(c(\n",
    "  0,0,1,\n",
    "  0,1,1,\n",
    "  1,0,1,\n",
    "  1,1,1\n",
    "), ncol = 3, byrow = TRUE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y <- c(0,1,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in nn$input %*% nn$weights1: requires numeric/complex matrix/vector arguments\n",
     "output_type": "error",
     "traceback": [
      "Error in nn$input %*% nn$weights1: requires numeric/complex matrix/vector arguments\nTraceback:\n",
      "1. NeuralNetwork(X, y, num_nodes = 4, num_iter = 1000)",
      "2. GD(nnet, num_iter)   # at line 18 of file <text>",
      "3. feedforward(nnet)   # at line 10 of file <text>",
      "4. sigmoid(nn$input %*% nn$weights1)   # at line 4 of file <text>"
     ]
    }
   ],
   "source": [
    "nn <- NeuralNetwork(X,y,num_nodes=4, num_iter=1000)#the number of nodes and interactions and learning rate and layers depend on us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 4 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Predicted</th><th scope=col>Actual</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.014</td><td>0</td></tr>\n",
       "\t<tr><td>0.963</td><td>1</td></tr>\n",
       "\t<tr><td>0.961</td><td>1</td></tr>\n",
       "\t<tr><td>0.047</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 4 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       " Predicted & Actual\\\\\n",
       " <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0.014 & 0\\\\\n",
       "\t 0.963 & 1\\\\\n",
       "\t 0.961 & 1\\\\\n",
       "\t 0.047 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 4 × 2\n",
       "\n",
       "| Predicted &lt;dbl&gt; | Actual &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| 0.014 | 0 |\n",
       "| 0.963 | 1 |\n",
       "| 0.961 | 1 |\n",
       "| 0.047 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  Predicted Actual\n",
       "1 0.014     0     \n",
       "2 0.963     1     \n",
       "3 0.961     1     \n",
       "4 0.047     0     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>iteration</th><th scope=col>loss</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>2</td><td>1.4510233</td></tr>\n",
       "\t<tr><td>3</td><td>1.1752769</td></tr>\n",
       "\t<tr><td>4</td><td>1.0071065</td></tr>\n",
       "\t<tr><td>5</td><td>0.9970509</td></tr>\n",
       "\t<tr><td>6</td><td>0.9969139</td></tr>\n",
       "\t<tr><td>7</td><td>0.9967774</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       " iteration & loss\\\\\n",
       " <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 2 & 1.4510233\\\\\n",
       "\t 3 & 1.1752769\\\\\n",
       "\t 4 & 1.0071065\\\\\n",
       "\t 5 & 0.9970509\\\\\n",
       "\t 6 & 0.9969139\\\\\n",
       "\t 7 & 0.9967774\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| iteration &lt;dbl&gt; | loss &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| 2 | 1.4510233 |\n",
       "| 3 | 1.1752769 |\n",
       "| 4 | 1.0071065 |\n",
       "| 5 | 0.9970509 |\n",
       "| 6 | 0.9969139 |\n",
       "| 7 | 0.9967774 |\n",
       "\n"
      ],
      "text/plain": [
       "  iteration loss     \n",
       "1 2         1.4510233\n",
       "2 3         1.1752769\n",
       "3 4         1.0071065\n",
       "4 5         0.9970509\n",
       "5 6         0.9969139\n",
       "6 7         0.9967774"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>iteration</th><th scope=col>loss</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>995</th><td> 996</td><td>0.005292026</td></tr>\n",
       "\t<tr><th scope=row>996</th><td> 997</td><td>0.005284726</td></tr>\n",
       "\t<tr><th scope=row>997</th><td> 998</td><td>0.005277444</td></tr>\n",
       "\t<tr><th scope=row>998</th><td> 999</td><td>0.005270181</td></tr>\n",
       "\t<tr><th scope=row>999</th><td>1000</td><td>0.005262938</td></tr>\n",
       "\t<tr><th scope=row>1000</th><td>1001</td><td>0.005255713</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & iteration & loss\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t995 &  996 & 0.005292026\\\\\n",
       "\t996 &  997 & 0.005284726\\\\\n",
       "\t997 &  998 & 0.005277444\\\\\n",
       "\t998 &  999 & 0.005270181\\\\\n",
       "\t999 & 1000 & 0.005262938\\\\\n",
       "\t1000 & 1001 & 0.005255713\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | iteration &lt;dbl&gt; | loss &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 995 |  996 | 0.005292026 |\n",
       "| 996 |  997 | 0.005284726 |\n",
       "| 997 |  998 | 0.005277444 |\n",
       "| 998 |  999 | 0.005270181 |\n",
       "| 999 | 1000 | 0.005262938 |\n",
       "| 1000 | 1001 | 0.005255713 |\n",
       "\n"
      ],
      "text/plain": [
       "     iteration loss       \n",
       "995   996      0.005292026\n",
       "996   997      0.005284726\n",
       "997   998      0.005277444\n",
       "998   999      0.005270181\n",
       "999  1000      0.005262938\n",
       "1000 1001      0.005255713"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn$yhat # the predicted gives us the probability to get 1\n",
    "head(nn$loss)# the loss is the error\n",
    "tail(nn$loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAABmJLR0QA/wD/AP+gvaeTAAAg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\nBgBQqP8HYUXFCdpT26YAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 240,
       "width": 240
      },
      "text/plain": {
       "height": 240,
       "width": 240
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width = 4, repr.plot.height = 4)\n",
    "\n",
    "# plot the cost\n",
    "library(ggplot2)\n",
    "\n",
    "ggplot(data = nn$loss, aes(x = iteration, y = loss)) +\n",
    "  geom_line()\n",
    "# we can see that after 250 interactions there is no more decrasing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
